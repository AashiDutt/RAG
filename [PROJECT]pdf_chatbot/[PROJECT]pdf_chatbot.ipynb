{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This repository reads any pdf document and uses local llama3 and RAG to chat with the document and get answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installations and Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain -q\n",
    "!pip install pymupdf -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import ollama\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1: READ PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='LLM-based Machine Translation Model\\nPipeline\\nStep 1: Dataset for pipeline\\nThis can include publicly available datasets or proprietary data that needs to be\\ngathered. The text should ideally be in diverse fonts, sizes, and backgrounds to\\nensure robust OCR performance. In case of legal documents, these can be old\\ndocuments being collected from the authorities.This dataset can be in the form of\\nimages or pdf.\\nOfficial document (text)\\n', metadata={'source': 'test_doc.pdf', 'file_path': 'test_doc.pdf', 'page': 0, 'total_pages': 8, 'format': 'PDF 1.4', 'title': 'KYROTICS | PROBLEM FOR LLM', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m124 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = PyMuPDFLoader(\"test_doc.pdf\")\n",
    "data = loader.load()\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2: CONVERT DOC INTO CHUNKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='LLM-based Machine Translation Model\\nPipeline\\nStep 1: Dataset for pipeline\\nThis can include publicly available datasets or proprietary data that needs to be\\ngathered. The text should ideally be in diverse fonts, sizes, and backgrounds to\\nensure robust OCR performance. In case of legal documents, these can be old\\ndocuments being collected from the authorities.This dataset can be in the form of\\nimages or pdf.\\nOfficial document (text)', metadata={'source': 'test_doc.pdf', 'file_path': 'test_doc.pdf', 'page': 0, 'total_pages': 8, 'format': 'PDF 1.4', 'title': 'KYROTICS | PROBLEM FOR LLM', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m124 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}),\n",
       " Document(page_content='Step 2: Text Extraction\\nOCR Extraction: Use an OCR (Optical Character Recognition) tool to extract the\\ntext from the image. This tool would recognize characters in the image and convert\\nthem into editable text.\\nPypdf(PdfReader) / pdfminer/ Tesseract/Camelot: To extract text from pdf,\\npreserving the whitespaces and interword spaces.\\nMethod for Proper text extraction with structure intact:\\nMethod 1: Using Vision API/ Gen AI tools (reference)\\nRead a PDF/PNG format document and, use the Vision API(google cloud vision\\nAPI) to get blocks of text from it.\\n1. Convert the entire PDF to PNG and serialize only the first page. Use the pdf2png\\nlibrary (convert pdf to png) for this. Use the Vision API to make a\\ndocument_text_detection() request for getting the dense text blocks.', metadata={'source': 'test_doc.pdf', 'file_path': 'test_doc.pdf', 'page': 1, 'total_pages': 8, 'format': 'PDF 1.4', 'title': 'KYROTICS | PROBLEM FOR LLM', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m124 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''})]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the RecursiveCharacterTextSplitter class to split the documents into chunks for embedding\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500, \n",
    "    chunk_overlap  = 100, \n",
    "    length_function = len,\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(data)\n",
    "\n",
    "# Look at the first two chunks \n",
    "chunks[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 8\n",
      "Number of chunks: 19\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of documents: {len(data)}')\n",
    "print(f'Number of chunks: {len(chunks)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP3: CONVERT CHUNKS TO EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(model = \"llama3\")\n",
    "vectorstore = Chroma.from_documents(documents = chunks, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP4: Put it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call llama3 model  (RAG - Generation part)\n",
    "def ollama_llm(question, context):\n",
    "    formatted_prompt = f\"Question: {question}\\n\\nContext: {context}\"\n",
    "    response = ollama.chat(model = \"llama3\", messages = [{'role': 'user', 'content': formatted_prompt}])\n",
    "    return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG - Retriever part\n",
    "retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_chain(question):\n",
    "    retrieved_docs = retriever.invoke(question)\n",
    "    formatted_content = combine_docs(retrieved_docs)\n",
    "    result = ollama_llm(question, formatted_content)\n",
    "    return {'result': result, 'source_documents': retrieved_docs}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(question:str):\n",
    "    response = rag_chain(question)\n",
    "    print(f\"Response: {response}\\n\")\n",
    "    citations = {doc.metadata['source'] for doc in response['source_documents']}\n",
    "    print(f\"Citations: {citations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: {'result': 'The document appears to be a proposal for a project that aims to improve the performance of English-Hindi translations by utilizing deep learning algorithms and cloud computing resources.\\n\\nThe proposal outlines the steps involved in achieving this goal, including:\\n\\n1. Developing a model using deep learning algorithms such as YOLOv5, CRAFT, or others designed specifically for text detection.\\n2. Drawing bounding boxes around detected text blocks to segregate them into individual text blocks.\\n3. Using Optical Character Recognition (OCR) on each text block to read the text and translate it from English to Hindi.\\n4. Overlaying the translated Hindi text onto the original image, replicating the original format, and replacing the English text with Hindi within the exact bounding box.\\n\\nThe proposal also includes an estimated budget for the project, which consists of salaries for a team of engineers (INR 72 lakhs), cloud computing costs (INR 10-15 lakhs), local hardware for hosting (INR 5-10 lakhs), and software and miscellaneous expenses (INR 3-5 lakhs). The total estimated budget is INR 90-102 lakhs, leaving some margin for contingencies within the INR 1 Crore budget.', 'source_documents': [Document(page_content='better performance for English-Hindi translations.\\nStep 4: Check model performance\\nCheck model performance on test data and look into metrics. Also, cross-check the\\ntranslated text with a linguist for human feedback.\\nStep 5: Overlay Text\\nThe final step would involve overlaying the translated Hindi text onto the original\\nimage, replicating the original format, and replacing the English text with Hindi\\nwithin the exact bounding box. Repeat for all pages and convert png back to PDF.', metadata={'author': '', 'creationDate': '', 'creator': '', 'file_path': 'test_doc.pdf', 'format': 'PDF 1.4', 'keywords': '', 'modDate': '', 'page': 4, 'producer': 'Skia/PDF m124 Google Docs Renderer', 'source': 'test_doc.pdf', 'subject': '', 'title': 'KYROTICS | PROBLEM FOR LLM', 'total_pages': 8, 'trapped': ''}), Document(page_content='●Salaries for Team: Assuming an average annual salary of INR 12 lakhs per\\nengineer for a team of 6, the total for one year would be approximately INR\\n72 lakhs.\\n●Cloud Computing Costs: Depending on the model size and training duration,\\nthis could range from INR 10-15 lakhs.\\n●Local Hardware for Hosting: Approximately INR 5-10 lakhs for a robust\\nserver setup.\\n●Software and Miscellaneous: Licenses, tools, and unforeseen expenses could\\namount to INR 3-5 lakhs.\\nTotal Estimated Budget: INR 90-102 lakhs, leaving some margin for contingencies\\nwithin the INR 1 Crore budget.', metadata={'author': '', 'creationDate': '', 'creator': '', 'file_path': 'test_doc.pdf', 'format': 'PDF 1.4', 'keywords': '', 'modDate': '', 'page': 7, 'producer': 'Skia/PDF m124 Google Docs Renderer', 'source': 'test_doc.pdf', 'subject': '', 'title': 'KYROTICS | PROBLEM FOR LLM', 'total_pages': 8, 'trapped': ''}), Document(page_content='designed for text detection. It is fast and accurate and can handle text of various\\norientations and sizes.\\nYOLOv5(latest v9): This is a general object detection algorithm that can also be\\nused for text detection. It is very fast and can handle a wide variety of object types,\\nincluding text.\\nCRAFT: This is another deep learning-based algorithm that is specifically\\ndesigned for text detection. It is particularly good at detecting curved text and text\\nthat is partially occluded.', metadata={'author': '', 'creationDate': '', 'creator': '', 'file_path': 'test_doc.pdf', 'format': 'PDF 1.4', 'keywords': '', 'modDate': '', 'page': 2, 'producer': 'Skia/PDF m124 Google Docs Renderer', 'source': 'test_doc.pdf', 'subject': '', 'title': 'KYROTICS | PROBLEM FOR LLM', 'total_pages': 8, 'trapped': ''}), Document(page_content='2. Draw a bounding box. The catch here is for dense text block detection, Vision API\\nreturns polygon coordinates and not rectangular coordinates. So, take polygon\\ncrops to segregate the different text blocks.\\n3. Use polygon crop to segregate text blocks, then apply OCR on text blocks to read\\ntext (use pytesseract/pypdf/pdfreader if using pdf).\\n4. Save the coordinates, we need to put back the text at the same block.', metadata={'author': '', 'creationDate': '', 'creator': '', 'file_path': 'test_doc.pdf', 'format': 'PDF 1.4', 'keywords': '', 'modDate': '', 'page': 1, 'producer': 'Skia/PDF m124 Google Docs Renderer', 'source': 'test_doc.pdf', 'subject': '', 'title': 'KYROTICS | PROBLEM FOR LLM', 'total_pages': 8, 'trapped': ''})]}\n",
      "\n",
      "Citations: {'test_doc.pdf'}\n"
     ]
    }
   ],
   "source": [
    "ask_question(\"What is the document about?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: {'result': 'The approximate cost for the whole project is INR 1 Crore (90-102 lakhs), leaving some margin for contingencies within the budget. The breakdown of costs is as follows:\\n\\n* Salaries for Team: approximately INR 72 lakhs (6 engineers x INR 12 lakhs per engineer)\\n* Cloud Computing Costs: INR 10-15 lakhs\\n* Local Hardware for Hosting: INR 5-10 lakhs\\n* Software and Miscellaneous: INR 3-5 lakhs\\n\\nTotal estimated budget: INR 90-102 lakhs (approximately INR 1 Crore)', 'source_documents': [Document(page_content='amount to INR 3-5 lakhs.\\nTotal Estimated Budget: INR 90-102 lakhs, leaving some margin for contingencies\\nwithin the INR 1 Crore budget.', metadata={'author': '', 'creationDate': '', 'creator': '', 'file_path': 'test_doc.pdf', 'format': 'PDF 1.4', 'keywords': '', 'modDate': '', 'page': 7, 'producer': 'Skia/PDF m124 Google Docs Renderer', 'source': 'test_doc.pdf', 'subject': '', 'title': 'KYROTICS | PROBLEM FOR LLM', 'total_pages': 8, 'trapped': ''}), Document(page_content='●Salaries for Team: Assuming an average annual salary of INR 12 lakhs per\\nengineer for a team of 6, the total for one year would be approximately INR\\n72 lakhs.\\n●Cloud Computing Costs: Depending on the model size and training duration,\\nthis could range from INR 10-15 lakhs.\\n●Local Hardware for Hosting: Approximately INR 5-10 lakhs for a robust\\nserver setup.\\n●Software and Miscellaneous: Licenses, tools, and unforeseen expenses could\\namount to INR 3-5 lakhs.', metadata={'author': '', 'creationDate': '', 'creator': '', 'file_path': 'test_doc.pdf', 'format': 'PDF 1.4', 'keywords': '', 'modDate': '', 'page': 7, 'producer': 'Skia/PDF m124 Google Docs Renderer', 'source': 'test_doc.pdf', 'subject': '', 'title': 'KYROTICS | PROBLEM FOR LLM', 'total_pages': 8, 'trapped': ''}), Document(page_content='The final step would involve overlaying the translated Hindi text onto the original\\nimage, replicating the original format, and replacing the English text with Hindi\\nwithin the exact bounding box. Repeat for all pages and convert png back to PDF.', metadata={'author': '', 'creationDate': '', 'creator': '', 'file_path': 'test_doc.pdf', 'format': 'PDF 1.4', 'keywords': '', 'modDate': '', 'page': 4, 'producer': 'Skia/PDF m124 Google Docs Renderer', 'source': 'test_doc.pdf', 'subject': '', 'title': 'KYROTICS | PROBLEM FOR LLM', 'total_pages': 8, 'trapped': ''}), Document(page_content='orientations and sizes.\\nYOLOv5(latest v9): This is a general object detection algorithm that can also be\\nused for text detection. It is very fast and can handle a wide variety of object types,\\nincluding text.\\nCRAFT: This is another deep learning-based algorithm that is specifically\\ndesigned for text detection. It is particularly good at detecting curved text and text\\nthat is partially occluded.', metadata={'author': '', 'creationDate': '', 'creator': '', 'file_path': 'test_doc.pdf', 'format': 'PDF 1.4', 'keywords': '', 'modDate': '', 'page': 2, 'producer': 'Skia/PDF m124 Google Docs Renderer', 'source': 'test_doc.pdf', 'subject': '', 'title': 'KYROTICS | PROBLEM FOR LLM', 'total_pages': 8, 'trapped': ''})]}\n",
      "\n",
      "Citations: {'test_doc.pdf'}\n"
     ]
    }
   ],
   "source": [
    "ask_question(\"What is the approximate cost for the whole project?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
